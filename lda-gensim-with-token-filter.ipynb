{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LDA - Gensim with token filtering\n",
        "\n",
        "Here, I'm using LDA model from gensim. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcOPoLTScu4V"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're in local machine, you should run this cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_PATH = \"./\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're in Google Colab, you should run this cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_PATH = \"<ENTER YOUR DRIVE PATH>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iW6IW_VNDJw"
      },
      "source": [
        "# Load Data\n",
        "Preprocessed training and testing data from \n",
        "[20-news-dataset-pre-processing](https://github.com/nimmitahsin1727/20-news-dataset-pre-processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1AubdN5uGOv"
      },
      "source": [
        "Reading TRAINING from CSV:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "57OiI3tpuF8Y"
      },
      "outputs": [],
      "source": [
        "training_df = pd.read_csv(f'{BASE_PATH}training_df.csv') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebrTGRCCvGsj"
      },
      "source": [
        "Reading TESTING from CSV:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dMD2yGOGvJkK"
      },
      "outputs": [],
      "source": [
        "testing_df = pd.read_csv(f'{BASE_PATH}testing_df.csv') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCWaUQJfKSWq"
      },
      "source": [
        "Create data_words with training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bX8K5yK_J6Cw"
      },
      "outputs": [],
      "source": [
        "data_words = training_df.data.map(lambda doc: word_tokenize(doc)).values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XPhDJXRWcbl"
      },
      "source": [
        "**Bag of Words on the Data set**\n",
        "\n",
        "Create a dictionary from `data_words` containing the number of times a word appears in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbhA7QotULal",
        "outputId": "08a3bae0-b93c-4e8e-b51b-0bcad288aef2"
      },
      "outputs": [],
      "source": [
        "dictionary = corpora.Dictionary(data_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Printing some samples from dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 actively\n",
            "1 ama\n",
            "2 apr\n",
            "3 assistance\n",
            "4 away\n",
            "5 big\n",
            "6 bike\n",
            "7 board\n",
            "8 camp\n",
            "9 childish\n",
            "10 count\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqPO8s2TWSy-"
      },
      "source": [
        "**Gensim filter_extremes**\n",
        "\n",
        "***Filter out tokens that appear in***\n",
        "\n",
        "less than 15 documents (absolute number) or\n",
        "more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
        "after the above two steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xflYCHdyUggY"
      },
      "outputs": [],
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSbcIn2kWJXm"
      },
      "source": [
        "**Gensim doc2bow**\n",
        "\n",
        "For each document we create a dictionary reporting how many\n",
        "words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NJ8Jp_1aUty_"
      },
      "outputs": [],
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in data_words]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCIFEKZlWFTk"
      },
      "source": [
        "Preview Bag Of Words for our sample preprocessed document.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-UMfDeHNVOUw"
      },
      "outputs": [],
      "source": [
        "bow_doc_123 = bow_corpus[123]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohTYek_MVhHM",
        "outputId": "c59b7432-37ae-4cbb-da8a-31c82769e81c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word 4 (\"bike\") appears 1 time.\n",
            "Word 7 (\"dod\") appears 2 time.\n",
            "Word 19 (\"make\") appears 1 time.\n",
            "Word 26 (\"say\") appears 2 time.\n",
            "Word 33 (\"work\") appears 1 time.\n",
            "Word 45 (\"good\") appears 1 time.\n",
            "Word 48 (\"just\") appears 1 time.\n",
            "Word 51 (\"like\") appears 1 time.\n",
            "Word 82 (\"old\") appears 1 time.\n",
            "Word 114 (\"thing\") appears 1 time.\n",
            "Word 135 (\"replyto\") appears 1 time.\n",
            "Word 150 (\"check\") appears 1 time.\n",
            "Word 156 (\"damage\") appears 1 time.\n",
            "Word 184 (\"right\") appears 1 time.\n",
            "Word 187 (\"spot\") appears 1 time.\n",
            "Word 193 (\"today\") appears 1 time.\n",
            "Word 211 (\"difference\") appears 1 time.\n",
            "Word 228 (\"piece\") appears 1 time.\n",
            "Word 243 (\"wish\") appears 1 time.\n",
            "Word 274 (\"year\") appears 1 time.\n",
            "Word 276 (\"corner\") appears 2 time.\n",
            "Word 309 (\"confuse\") appears 1 time.\n",
            "Word 311 (\"delete\") appears 1 time.\n",
            "Word 321 (\"mike\") appears 1 time.\n",
            "Word 350 (\"hit\") appears 2 time.\n",
            "Word 351 (\"home\") appears 1 time.\n",
            "Word 381 (\"honda\") appears 1 time.\n",
            "Word 404 (\"day\") appears 1 time.\n",
            "Word 448 (\"list\") appears 1 time.\n",
            "Word 458 (\"okay\") appears 1 time.\n",
            "Word 464 (\"pull\") appears 1 time.\n",
            "Word 485 (\"foot\") appears 1 time.\n",
            "Word 487 (\"ground\") appears 1 time.\n",
            "Word 493 (\"previous\") appears 1 time.\n",
            "Word 553 (\"answer\") appears 1 time.\n",
            "Word 556 (\"change\") appears 1 time.\n",
            "Word 559 (\"couple\") appears 1 time.\n",
            "Word 575 (\"turn\") appears 1 time.\n",
            "Word 587 (\"feel\") appears 1 time.\n",
            "Word 591 (\"loss\") appears 1 time.\n",
            "Word 636 (\"michael\") appears 1 time.\n",
            "Word 687 (\"canada\") appears 1 time.\n",
            "Word 688 (\"contact\") appears 1 time.\n",
            "Word 689 (\"contribute\") appears 1 time.\n",
            "Word 734 (\"pipe\") appears 2 time.\n",
            "Word 764 (\"buck\") appears 1 time.\n",
            "Word 790 (\"happen\") appears 1 time.\n",
            "Word 828 (\"miss\") appears 1 time.\n",
            "Word 906 (\"cause\") appears 1 time.\n",
            "Word 957 (\"thought\") appears 1 time.\n",
            "Word 1021 (\"indian\") appears 1 time.\n",
            "Word 1026 (\"news\") appears 1 time.\n",
            "Word 1083 (\"opportunity\") appears 1 time.\n",
            "Word 1130 (\"engineering\") appears 1 time.\n",
            "Word 1164 (\"joke\") appears 1 time.\n",
            "Word 1173 (\"month\") appears 1 time.\n",
            "Word 1188 (\"past\") appears 1 time.\n",
            "Word 1225 (\"suspect\") appears 1 time.\n",
            "Word 1264 (\"accidental\") appears 1 time.\n",
            "Word 1265 (\"compress\") appears 1 time.\n",
            "Word 1266 (\"degree\") appears 1 time.\n",
            "Word 1308 (\"squid\") appears 1 time.\n",
            "Word 1351 (\"chief\") appears 1 time.\n",
            "Word 1383 (\"scratch\") appears 1 time.\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(bow_doc_123)):\n",
        "    print(f'Word {bow_doc_123[i][0]} (\\\"{dictionary[bow_doc_123[i][0]]}\\\") appears {bow_doc_123[i][1]} time.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS1jG-vbXsWo"
      },
      "source": [
        "**Running LDA using Bag of Words**\n",
        "\n",
        "Train our lda model using gensim.models.LdaMulticore and save it to lda_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DJVJRU3Xl9u",
        "outputId": "a8594686-89cb-45b4-9adc-f154fc840762"
      },
      "outputs": [],
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the Keyword in the 10 topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lKG4Z4UX3y7",
        "outputId": "647abfab-507f-47f3-e719-b6f281a0a144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.019*\"gun\" + 0.015*\"use\" + 0.012*\"image\" + 0.009*\"like\" + 0.008*\"make\" + '\n",
            "  '0.006*\"file\" + 0.006*\"right\" + 0.006*\"just\" + 0.006*\"know\" + '\n",
            "  '0.005*\"program\"'),\n",
            " (1,\n",
            "  '0.009*\"say\" + 0.008*\"make\" + 0.008*\"fbi\" + 0.007*\"right\" + 0.007*\"gun\" + '\n",
            "  '0.006*\"just\" + 0.006*\"time\" + 0.006*\"start\" + 0.006*\"like\" + 0.005*\"good\"'),\n",
            " (2,\n",
            "  '0.016*\"bike\" + 0.010*\"like\" + 0.008*\"right\" + 0.008*\"time\" + 0.008*\"just\" + '\n",
            "  '0.008*\"say\" + 0.007*\"make\" + 0.006*\"dod\" + 0.006*\"gun\" + 0.006*\"use\"'),\n",
            " (3,\n",
            "  '0.025*\"file\" + 0.008*\"good\" + 0.006*\"use\" + 0.006*\"know\" + 0.005*\"make\" + '\n",
            "  '0.005*\"image\" + 0.005*\"world\" + 0.005*\"need\" + 0.005*\"like\" + '\n",
            "  '0.005*\"graphic\"'),\n",
            " (4,\n",
            "  '0.018*\"image\" + 0.009*\"graphic\" + 0.009*\"file\" + 0.009*\"point\" + '\n",
            "  '0.008*\"use\" + 0.007*\"package\" + 0.007*\"know\" + 0.006*\"software\" + '\n",
            "  '0.006*\"data\" + 0.006*\"look\"'),\n",
            " (5,\n",
            "  '0.009*\"jpeg\" + 0.009*\"bike\" + 0.008*\"dod\" + 0.008*\"behanna\" + 0.008*\"use\" + '\n",
            "  '0.007*\"right\" + 0.007*\"know\" + 0.006*\"state\" + 0.006*\"image\" + '\n",
            "  '0.006*\"file\"'),\n",
            " (6,\n",
            "  '0.010*\"use\" + 0.008*\"good\" + 0.008*\"knife\" + 0.008*\"know\" + 0.007*\"card\" + '\n",
            "  '0.007*\"just\" + 0.007*\"gun\" + 0.006*\"say\" + 0.006*\"like\" + 0.005*\"bike\"'),\n",
            " (7,\n",
            "  '0.010*\"know\" + 0.010*\"make\" + 0.009*\"helmet\" + 0.009*\"say\" + 0.009*\"bike\" + '\n",
            "  '0.008*\"just\" + 0.008*\"use\" + 0.007*\"like\" + 0.006*\"child\" + 0.006*\"want\"'),\n",
            " (8,\n",
            "  '0.015*\"use\" + 0.010*\"know\" + 0.009*\"like\" + 0.008*\"dog\" + 0.007*\"polygon\" + '\n",
            "  '0.006*\"apr\" + 0.006*\"bike\" + 0.006*\"just\" + 0.006*\"point\" + 0.006*\"look\"'),\n",
            " (9,\n",
            "  '0.017*\"gun\" + 0.008*\"state\" + 0.008*\"make\" + 0.008*\"file\" + 0.007*\"use\" + '\n",
            "  '0.007*\"say\" + 0.006*\"law\" + 0.006*\"right\" + 0.006*\"know\" + 0.006*\"just\"')]\n"
          ]
        }
      ],
      "source": [
        "pprint(lda_model.print_topics())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UcOPoLTScu4V",
        "S_BBNjjzc4m5",
        "c0cAeBowGUVP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "6787912cc06540c826098c2e9891f9672e6365160866aa38805d4b2fc3d28660"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
